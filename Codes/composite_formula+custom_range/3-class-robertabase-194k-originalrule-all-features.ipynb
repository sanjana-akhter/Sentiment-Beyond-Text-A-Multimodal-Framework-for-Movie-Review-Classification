{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13813070,"sourceType":"datasetVersion","datasetId":8795628}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- INSTALLING LIBRARIES ---\n!pip install --upgrade transformers accelerate datasets scikit-learn -q\n\n# --- IMPORTING LIBRARIES ---\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, RobertaModel, TrainingArguments, Trainer # CHANGE 1 & 2: Replaced DistilBertModel with RobertaModel\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, MultiLabelBinarizer, OneHotEncoder\nfrom sklearn.utils.class_weight import compute_class_weight \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\nRNG = 42\n\n# --- LOADING THE DATASET ---\n\n# âœ… FIXED PATH BELOW\nFILE_PATH = '/kaggle/input/original-rule-194/Original_Rule_0_4_7_10_194k.csv' \n\nprint(f\"Loading dataset from: {FILE_PATH}\")\n\ntry:\n    df = pd.read_csv(FILE_PATH)\nexcept FileNotFoundError:\n    print(\"\\nâŒ ERROR: File not found!\")\n    print(f\"Please verify the path: {FILE_PATH}\")\n    print(\"Tip: In Kaggle, check the 'Input' section on the right sidebar to copy the exact path.\")\n    raise\n\n# --- SANITY CHECK ---\nneeded_cols = [\n    'title', 'reviewText', 'audienceScore', 'tomatoMeter', 'runtimeMinutes',\n    'genre', 'language_encoded', 'director_encoded', 'target_label'\n]\n\nmissing = [c for c in needed_cols if c not in df.columns]\nif missing:\n    raise ValueError(f\"âŒ CRITICAL ERROR: Your CSV is missing these columns: {missing}\")\n\nprint(\"--- Part 1: Setup and Data Loading Complete (Kaggle Version) ---\")\nprint(f\"Dataset loaded with {df.shape[0]} rows.\")\nprint(f\"Target Distribution:\\n{df['target_label'].value_counts().sort_index()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T07:12:36.162729Z","iopub.execute_input":"2025-11-21T07:12:36.162897Z","iopub.status.idle":"2025-11-21T07:14:36.145050Z","shell.execute_reply.started":"2025-11-21T07:12:36.162881Z","shell.execute_reply":"2025-11-21T07:14:36.144190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 2: PREPROCESSING & FEATURE ENGINEERING ---\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, MultiLabelBinarizer, OneHotEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom packaging import version\nimport sklearn\n\n# Ensure 'df' and 'RNG' exist from Part 1\nif 'df' not in globals():\n    raise ValueError(\"âŒ 'df' is missing! Please run Part 1 to load the data first.\")\n\n# --- CLEANING ---\nprint(\"Cleaning data...\")\ndf = df.dropna(subset=['reviewText', 'target_label']).copy()\n# Map 'target_label' to the standard 'label' column expected by HF\ndf['label'] = df['target_label'].astype(int)\n\nclass_names = ['Negative', 'Neutral', 'Positive']\nN_CLASSES = 3\n\n# Text Prep\ndf['title'] = df['title'].fillna(\"\")\ndf['genre'] = df['genre'].fillna(\"Unknown\")\ndf['combined_text'] = df['title'] + \" [SEP] \" + df['reviewText']\n\n# --- STRATIFIED SPLIT ---\nprint(\"Splitting data (Stratified)...\")\ntrain_idx, test_idx = train_test_split(\n    df.index, test_size=0.2, random_state=RNG, stratify=df['label']\n)\ntrain_df = df.loc[train_idx].reset_index(drop=True)\ntest_df  = df.loc[test_idx].reset_index(drop=True)\n\ny_train = train_df['label'].values.astype(int)\n\n# ==========================================\n# CRITICAL: CALCULATE CLASS WEIGHTS\n# ==========================================\nprint(\"Calculating class weights...\")\n# This forces the model to pay attention to minority classes\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(y_train),\n    y=y_train\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float)\nprint(\"\\nâš–ï¸ Calculated Class Weights (Neg, Neu, Pos):\")\nprint(class_weights)\nprint(\"(The model will use these to penalize mistakes on smaller classes more heavily)\")\n\n# ==========================================\n# FEATURE ENGINEERING (Fit on Train)\n# ==========================================\nprint(\"Starting Feature Engineering...\")\n\n# 1. Numeric\nprint(\"-> Processing Numeric features...\")\nNUMERIC_COLS = ['tomatoMeter', 'audienceScore', 'runtimeMinutes']\ntrain_numeric = train_df[NUMERIC_COLS].copy()\ntrain_medians = train_numeric.median(numeric_only=True)\ntrain_numeric = train_numeric.fillna(train_medians)\n\nscaler = StandardScaler()\nscaler.fit(train_numeric.values)\n\n# 2. Categorical: Genre\nprint(\"-> Processing Genre...\")\ntrain_genre_list = train_df['genre'].fillna(\"Unknown\").str.split(', ')\nmlb = MultiLabelBinarizer()\nmlb.fit(train_genre_list)\n\n# 3. Categorical: Language\nprint(\"-> Processing Language...\")\ntrain_lang = train_df['language_encoded'].astype('Int64').astype(str).fillna('unknown')\n\n# Handle sklearn version differences (Kaggle usually has the latest, but this is safe)\nif version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n    ohe_lang = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype=np.float32)\nelse:\n    ohe_lang = OneHotEncoder(handle_unknown='ignore', sparse=False, dtype=np.float32)\n\nohe_lang.fit(train_lang.to_frame())\n\n# 4. Categorical: Director (Robust Target Encoding)\nprint(\"-> Processing Director (Target Encoding)...\")\ndef director_features_multiclass(train_s, y, test_s, n_splits=5):\n    s_train = train_s.fillna(\"Unknown\").astype(str)\n    s_test  = test_s.fillna(\"Unknown\").astype(str)\n\n    # Frequency\n    freq = s_train.value_counts()\n    tr_freq = np.log1p(s_train.map(freq).fillna(0).values)[:, None].astype(np.float32)\n    te_freq = np.log1p(s_test.map(freq).fillna(0).values)[:, None].astype(np.float32)\n\n    # K-Fold Target Mean\n    n_classes = len(np.unique(y))\n    y_ohe = OneHotEncoder(categories=[range(n_classes)], sparse_output=False, dtype=np.float32).fit_transform(y.reshape(-1, 1))\n    global_mean = y_ohe.mean(axis=0)\n\n    tr_te = np.zeros((len(s_train), n_classes), dtype=np.float32)\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RNG)\n\n    for tr_i, val_i in skf.split(np.zeros(len(y)), y):\n        tr_fold = s_train.iloc[tr_i]\n        # Compute means\n        fold_means = pd.DataFrame(y_ohe[tr_i], index=tr_fold.index).groupby(tr_fold).mean()\n\n        # Map to validation\n        val_fold = s_train.iloc[val_i].to_frame(name='did')\n        merged = val_fold.merge(fold_means, left_on='did', right_index=True, how='left')\n        vals = merged.drop('did', axis=1).values\n\n        # Fill NaN with global mean\n        mask = np.isnan(vals.sum(axis=1))\n        vals[mask] = global_mean\n        tr_te[val_i] = vals.astype(np.float32)\n\n    # Test set mapping (using full train)\n    full_means = pd.DataFrame(y_ohe, index=s_train.index).groupby(s_train).mean()\n    test_df_map = s_test.to_frame(name='did')\n    merged_test = test_df_map.merge(full_means, left_on='did', right_index=True, how='left')\n    te_te = merged_test.drop('did', axis=1).values\n    mask_test = np.isnan(te_te.sum(axis=1))\n    te_te[mask_test] = global_mean\n\n    return tr_freq, te_freq, tr_te, te_te\n\n# Apply Director Encoding\ndtr_f, dte_f, dtr_te, dte_te = director_features_multiclass(\n    train_df['director_encoded'].astype(str), y_train,\n    test_df['director_encoded'].astype(str)\n)\n\ndir_train_block = np.concatenate([dtr_f, dtr_te], axis=1).astype(np.float32)\ndir_test_block  = np.concatenate([dte_f, dte_te], axis=1).astype(np.float32)\n\nprint(\"--- Part 2: Preprocessing & Weights Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T07:14:36.147292Z","iopub.execute_input":"2025-11-21T07:14:36.147697Z","iopub.status.idle":"2025-11-21T07:14:37.389870Z","shell.execute_reply.started":"2025-11-21T07:14:36.147667Z","shell.execute_reply":"2025-11-21T07:14:37.389194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 3: DATASET CREATION & TOKENIZATION ---\n\nimport numpy as np\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer\n\n# Ensure prerequisites from Part 2 exist\nrequired_vars = ['train_df', 'test_df', 'dir_train_block', 'dir_test_block', 'scaler', 'mlb', 'ohe_lang', 'train_medians']\nif not all(v in globals() for v in required_vars):\n    raise ValueError(\"âŒ Missing variables from Part 2. Please run the previous cell first.\")\n\n# Define helper function\ndef build_features(split_df, dir_block):\n    out = {}\n    out['combined_text'] = split_df['combined_text'].tolist()\n    out['label'] = split_df['label'].astype(int).tolist()\n\n    # Numeric\n    # NUMERIC_COLS was defined in Part 2\n    numeric = split_df[NUMERIC_COLS].copy().fillna(train_medians)\n    out['numerical_features'] = scaler.transform(numeric.values).astype(np.float32)\n\n    # Genre\n    genre_list = split_df['genre'].fillna(\"Unknown\").str.split(', ')\n    \n    # Concatenate all categorical features\n    out['categorical_features'] = np.concatenate([\n        mlb.transform(genre_list),\n        ohe_lang.transform(split_df['language_encoded'].astype('Int64').astype(str).fillna('unknown').to_frame()),\n        dir_block\n    ], axis=1).astype(np.float32)\n    \n    return out\n\nprint(\"Building features dictionaries...\")\ntrain_feats = build_features(train_df, dir_train_block)\ntest_feats  = build_features(test_df, dir_test_block)\n\n# Dimensions\nnum_numerical_features = 3\nnum_categorical_features = train_feats['categorical_features'].shape[1]\nprint(f\"Feature Dims: Numeric={num_numerical_features}, Categorical={num_categorical_features}\")\n\n# HF Dataset\nprint(\"Converting to Hugging Face Datasets...\")\nraw_datasets = DatasetDict({\n    'train': Dataset.from_dict(train_feats),\n    'test':  Dataset.from_dict(test_feats),\n})\n\n# Tokenization\n# ðŸ’¥ CHANGE 1: Swapping 'roberta-large' for 'roberta-base'\nMODEL_CHECKPOINT = \"roberta-base\" \n\nprint(f\"Downloading Tokenizer ({MODEL_CHECKPOINT})...\")\n# âš ï¸ KAGGLE NOTE: Ensure 'Internet' is enabled in the Settings sidebar!\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\nexcept Exception as e:\n    print(\"\\nâŒ ERROR: Could not download tokenizer.\")\n    print(\"Please check if 'Internet' is enabled in the Kaggle Notebook settings (Right Sidebar > Settings > Internet 'On').\")\n    raise e\n\ndef tokenize_fn(examples):\n    # The max_length=256 remains a good default for RoBERTa.\n    return tokenizer(examples[\"combined_text\"], padding=\"max_length\", truncation=True, max_length=256)\n\nprint(\"Tokenizing dataset (this may take a moment)...\")\ntokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns([\"combined_text\"])\ntokenized_datasets.set_format(\"torch\")\n\nprint(\"--- Part 3: Dataset Ready & Tokenized ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T07:14:37.390650Z","iopub.execute_input":"2025-11-21T07:14:37.390902Z","iopub.status.idle":"2025-11-21T07:15:10.531967Z","shell.execute_reply.started":"2025-11-21T07:14:37.390879Z","shell.execute_reply":"2025-11-21T07:15:10.531337Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 4: MODEL SETUP & TRAINING (KAGGLE VERSION - FIXED) ---\n\nimport torch\nimport torch.nn as nn\nfrom transformers import Trainer, TrainingArguments, RobertaModel \nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\nimport os\n\n# --- SAFETY CHECK ---\nif 'class_weights' not in globals():\n    raise ValueError(\"âŒ 'class_weights' is missing! Please run Part 2 first.\")\nif 'MODEL_CHECKPOINT' not in globals():\n    raise ValueError(\"âŒ 'MODEL_CHECKPOINT' is missing! Please run Part 3 first.\")\n\n# --- MODEL ARCHITECTURE ---\nclass MultimodalClassifier(nn.Module):\n    def __init__(self, num_labels, num_numerical, num_categorical):\n        super().__init__()\n        # The underlying model class is still RobertaModel\n        self.roberta = RobertaModel.from_pretrained(MODEL_CHECKPOINT) \n        self.dropout = nn.Dropout(0.2)\n        self.classifier = nn.Linear(\n            # Hidden size is automatically picked up via MODEL_CHECKPOINT ('roberta-base' is smaller)\n            self.roberta.config.hidden_size + num_numerical + num_categorical,\n            num_labels\n        )\n        self.num_labels = num_labels\n\n    def forward(self, input_ids, attention_mask, numerical_features, categorical_features, labels=None):\n        roberta_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = self.dropout(roberta_output.last_hidden_state[:, 0])\n\n        combined = torch.cat([pooled_output, numerical_features, categorical_features], dim=1)\n        logits = self.classifier(combined)\n\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n\n        return (loss, logits) if loss is not None else (None, logits)\n\n# --- CUSTOM TRAINER (FIXED FOR DATAPARALLEL) ---\nclass WeightedTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        labels = inputs.get(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs[1]\n\n        if hasattr(model, \"module\"):\n            classifier_layer = model.module.classifier\n        else:\n            classifier_layer = model.classifier\n\n        # Move weights to the correct device\n        weights = class_weights.to(classifier_layer.weight.device)\n\n        # Weighted Loss Calculation\n        loss_fct = nn.CrossEntropyLoss(weight=weights)\n        loss = loss_fct(logits.view(-1, self.model.num_labels), labels.view(-1))\n\n        return (loss, outputs) if return_outputs else loss\n\n# --- DATA COLLATOR, METRICS, INITIALIZATION (No Change) ---\nclass MultimodalDataCollator:\n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n    def __call__(self, features):\n        batch = self.tokenizer.pad(\n            [{\"input_ids\": f[\"input_ids\"], \"attention_mask\": f[\"attention_mask\"]} for f in features],\n            return_tensors=\"pt\"\n        )\n        batch['labels'] = torch.tensor([f['label'] for f in features], dtype=torch.long)\n        batch['numerical_features'] = torch.stack([f['numerical_features'] for f in features])\n        batch['categorical_features'] = torch.stack([f['categorical_features'] for f in features])\n        return batch\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    \n    if isinstance(pred.predictions, tuple):\n        predictions = pred.predictions[0]\n    else:\n        predictions = pred.predictions\n        \n    preds = predictions.argmax(-1)\n\n    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n    acc = accuracy_score(labels, preds)\n    \n    return {'accuracy': acc, 'f1_weighted': f1, 'precision': prec, 'recall': rec}\n\nmodel = MultimodalClassifier(N_CLASSES, num_numerical_features, num_categorical_features)\n\n# ðŸ’¥ CHANGE 1: Update the output directory name to reflect RoBERTa-base\nOUTPUT_DIR = \"/kaggle/working/Model_Results_3Class_Weighted_RoBERTa_Base_C2\" \n\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    learning_rate=2e-5,\n    # ðŸ’¥ CHANGE 2: Increase Batch Size (e.g., from 8 back to 16)\n    # RoBERTa-base (125M params) is much smaller than RoBERTa-large (355M params).\n    per_device_train_batch_size=16, \n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_weighted\",  \n    greater_is_better=True,\n    save_total_limit=2,\n    report_to=\"none\",\n    logging_steps=100,\n    fp16=True \n)\n\ntrainer = WeightedTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    data_collator=MultimodalDataCollator(tokenizer),\n    compute_metrics=compute_metrics,\n)\n\nprint(f\"--- Part 4: RoBERTa-base Weighted Training Setup Complete ---\")\nprint(f\"Saving checkpoints to: {OUTPUT_DIR}\")\nprint(f\"Training Batch Size: {training_args.per_device_train_batch_size}\")\ntrainer.train()\nprint(\"--- Training Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T07:15:10.532750Z","iopub.execute_input":"2025-11-21T07:15:10.533030Z","iopub.status.idle":"2025-11-21T10:32:50.193522Z","shell.execute_reply.started":"2025-11-21T07:15:10.532972Z","shell.execute_reply":"2025-11-21T10:32:50.192800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 5: EVALUATION & SAVING (KAGGLE VERSION) ---\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport shutil # For zipping the model\n\n# ==========================\n# EVALUATE â€¢ REPORT â€¢ PLOTS â€¢ SAVE\n# ==========================\nprint(\"\\n--- Final Evaluation on Test Set ---\")\n\n# 1. PLOT LOSS CURVES\n# Access logs\nlog_history = trainer.state.log_history\ntrain_logs = [log for log in log_history if ('loss' in log and 'eval_loss' not in log)]\neval_logs = [log for log in log_history if ('eval_loss' in log)]\n\nplt.figure(figsize=(12, 5))\n\n# Loss Plot\nplt.subplot(1, 2, 1)\nplt.plot([log.get('epoch', i) for i, log in enumerate(train_logs, 1)], [log['loss'] for log in train_logs], label='Training Loss')\nplt.plot([log.get('epoch', i) for i, log in enumerate(eval_logs, 1)], [log['eval_loss'] for log in eval_logs], label='Validation Loss')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Training vs Validation Loss'); plt.legend()\n\n\n# Accuracy Plot\nplt.subplot(1, 2, 2)\nif len(eval_logs) > 0 and 'eval_accuracy' in eval_logs[0]:\n    plt.plot([log.get('epoch', i) for i, log in enumerate(eval_logs, 1)], [log['eval_accuracy'] for log in eval_logs], label='Validation Accuracy')\n    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Validation Accuracy'); plt.legend()\nplt.tight_layout(); plt.show()\n\n# 2. PREDICTIONS (FIXED & SAFE)\nprint(\"Generating predictions...\")\npreds_output = trainer.predict(tokenized_datasets[\"test\"])\n\n# --- SAFETY CHECK START ---\nif isinstance(preds_output.predictions, tuple):\n    logits = preds_output.predictions[0]  # Extract logits if it's a tuple\nelse:\n    logits = preds_output.predictions     # Use directly if it's an array\n# --- SAFETY CHECK END ---\n\npred_labels = np.argmax(logits, axis=-1)\ntrue_labels = np.array(tokenized_datasets[\"test\"][\"label\"])\n\n# 3. CLASSIFICATION REPORT (Updated to 4 decimal places)\nprint(\"\\n--- Classification Report ---\")\nreport_dict = classification_report(true_labels, pred_labels, target_names=class_names, output_dict=True)\n\n# digits=4 for detailed precision\nprint(classification_report(true_labels, pred_labels, target_names=class_names, digits=4))\n\n# 4. CONFUSION MATRIX (Updated to 4 decimal places)\ncm = confusion_matrix(true_labels, pred_labels)\ncm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nplt.figure(figsize=(12, 5))\n\n# Counts (Integers)\nplt.subplot(1, 2, 1)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix (Counts)')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\n# Normalized (Floats with 4 decimals)\nplt.subplot(1, 2, 2)\nsns.heatmap(cm_norm, annot=True, fmt='.4f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix (Normalized)')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\n\nplt.tight_layout()\nplt.show()\n\n# 5. PER-CLASS BAR CHART\nreport_df = pd.DataFrame(report_dict).transpose()\nreport_df_classes = report_df.loc[[cn for cn in class_names if cn in report_df.index]]\nax = report_df_classes[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize=(10, 6))\nplt.title('Per-Class Metrics (Weighted Model)')\nplt.xlabel('Classes'); plt.ylabel('Score')\nplt.xticks(rotation=0); plt.grid(axis='y', linestyle='--'); plt.legend(loc='lower right')\nplt.show()\n\n# 6. SAVE (KAGGLE SPECIFIC)\n# Kaggle saves to /kaggle/working/\nFINAL_MODEL_DIR = \"Final_Model_3Class_RobertaB_OriginalRule_194k\" \nFINAL_MODEL_PATH = f\"/kaggle/working/{FINAL_MODEL_DIR}\"\n\nprint(f\"\\nðŸ’¾ Saving model to {FINAL_MODEL_PATH}...\")\ntrainer.save_model(FINAL_MODEL_PATH)\n\n# --- ZIP FOR DOWNLOAD ---\n# Kaggle makes it hard to download folders. We zip it so you can download 1 file.\nprint(\"ðŸ“¦ Zipping model for easy download...\")\nshutil.make_archive(f\"/kaggle/working/{FINAL_MODEL_DIR}\", 'zip', FINAL_MODEL_PATH)\n\nprint(f\"âœ… DONE! You can now download '{FINAL_MODEL_DIR}.zip' from the 'Output' tab on the right.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T10:32:50.194417Z","iopub.execute_input":"2025-11-21T10:32:50.194640Z","iopub.status.idle":"2025-11-21T10:38:02.206947Z","shell.execute_reply.started":"2025-11-21T10:32:50.194622Z","shell.execute_reply":"2025-11-21T10:38:02.206180Z"}},"outputs":[],"execution_count":null}]}